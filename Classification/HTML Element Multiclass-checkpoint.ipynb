{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kelse\\Anaconda3\\new\\lib\\site-packages\\sklearn\\feature_extraction\\image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n",
      "C:\\Users\\kelse\\Anaconda3\\new\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\kelse\\Anaconda3\\new\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\kelse\\Anaconda3\\new\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
      "C:\\Users\\kelse\\Anaconda3\\new\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\Users\\kelse\\Anaconda3\\new\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\Users\\kelse\\Anaconda3\\new\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "C:\\Users\\kelse\\Anaconda3\\new\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\kelse\\Anaconda3\\new\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\kelse\\Anaconda3\\new\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\kelse\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\kelse\\\\OneDrive\\\\Documents\\\\GitHub\\\\HTMLElementClassifier\\\\Dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-602b052161d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Import Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"C:\\Users\\kelse\\OneDrive\\Documents\\GitHub\\HTMLElementClassifier\\Dataset\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"ISO-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\new\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\new\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\new\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\new\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\new\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\new\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\new\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"encoding_errors\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"strict\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m         )\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\new\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m             )\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\kelse\\\\OneDrive\\\\Documents\\\\GitHub\\\\HTMLElementClassifier\\\\Dataset'"
     ]
    }
   ],
   "source": [
    "#Set Random seed\n",
    "np.random.seed(500)\n",
    "\n",
    "# Import Data\n",
    "df = pd.read_csv(r\"C:\\Users\\kelse\\OneDrive\\Documents\\GitHub\\HTMLElementClassifier\\Dataset\",encoding = \"ISO-8859-1\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Size of dataset\n",
    "df.shape\n",
    "df.dropna(\n",
    "    axis=0,\n",
    "    how='any',\n",
    "    thresh=None,\n",
    "    subset=None,\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Categories')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['HTMLElement'].dropna(inplace=True)\n",
    "df['Category'].value_counts().plot(kind='bar', figsize=(7, 6), rot=0)\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.xlabel(\"Categories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      ['input', 'twotabsearchtextbox', 'auto', 'sear...\n",
      "1      ['input', 'list', 'false', 'search', 'anything...\n",
      "2             ['input', 'search', 'label', 'q', 'input']\n",
      "3      ['input', 'text', 'iphone', 'pro', 'max', 'cas...\n",
      "4      ['input', 'twotabsearchtextbox', 'auto', 'sear...\n",
      "                             ...                        \n",
      "343                        ['btn', 'button', 'checkout']\n",
      "350       ['http', 'button', 'true', 'http', 'checkout']\n",
      "361    ['button', 'button', 'red', 'full', 'span', 'b...\n",
      "367    ['button', 'button', 'activepressed', 'checkout']\n",
      "376    ['button', 'button', 'disable', 'quickpaymode'...\n",
      "Name: text_final, Length: 402, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['HTMLElement'] = [entry.lower() for entry in df['HTMLElement']] #change lowercase\n",
    "df['HTMLElement']= [word_tokenize(entry) for entry in df['HTMLElement']] #perform tokenization\n",
    "\n",
    "# lemmantizazing\n",
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "\n",
    "\n",
    "for index,entry in enumerate(df['HTMLElement']):\n",
    "    # Declaring Empty List to store the words that follow the rules for this step\n",
    "    Final_words = []\n",
    "    # Initializing WordNetLemmatizer()\n",
    "    word_Lemmatized = WordNetLemmatizer()\n",
    "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "    for word, tag in pos_tag(entry):\n",
    "        # Below condition is to check for Stop words and consider only alphabets\n",
    "        if word not in stopwords.words('english') and word.isalpha():\n",
    "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "            Final_words.append(word_Final)\n",
    "    # The final processed set of words for each iteration will be stored in 'text_final'\n",
    "    df.loc[index,'text_final'] = str(Final_words)\n",
    "    \n",
    "print(df['text_final'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split model\n",
    "x_Train, x_Test, y_Train, y_Test = model_selection.train_test_split(df['text_final'].astype(str),df['Category'],test_size=0.33)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_Train = encoder.fit_transform(y_Train.astype(str))\n",
    "y_Test = encoder.fit_transform(y_Train.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   abebooks  absolute  action  activedsknav  add  addcart  addtobag  \\\n",
      "0         0         0       0             0    0        0         0   \n",
      "1         0         0       0             0    0        0         0   \n",
      "2         0         0       0             0    0        0         0   \n",
      "3         0         0       0             0    0        0         0   \n",
      "4         0         0       0             0    0        0         0   \n",
      "\n",
      "   addtobagbutton  addtobagid  addtobasket  ...  work  wrong  wwlgu  xlarge  \\\n",
      "0               0           0            0  ...     0      0      0       0   \n",
      "1               0           0            0  ...     0      0      0       0   \n",
      "2               0           0            0  ...     0      0      0       0   \n",
      "3               0           0            0  ...     0      0      0       0   \n",
      "4               0           0            0  ...     0      0      0       0   \n",
      "\n",
      "   xlink  xml  year  zoek  zonesource  zssjk  \n",
      "0      0    0     0     0           0      0  \n",
      "1      0    0     0     0           0      0  \n",
      "2      0    0     0     0           0      0  \n",
      "3      0    0     0     0           0      0  \n",
      "4      0    0     0     0           0      0  \n",
      "\n",
      "[5 rows x 672 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(184, 672)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BagOfWords Approach \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(df['text_final'].astype(str))\n",
    "df_bow_sklearn = pd.DataFrame(X.toarray(),columns=vectorizer.get_feature_names())\n",
    "print(df_bow_sklearn.head())\n",
    "\n",
    "Train_X = vectorizer.transform(x_Train)\n",
    "Test_X = vectorizer.transform(x_Test)\n",
    "\n",
    "Train_X.reshape(-1,1)\n",
    "Test_X.reshape(-1,1)\n",
    "\n",
    "Train_X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'naive_bayes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2516089e20de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Multinomial Naive Bayes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnaive_bayes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultinomialNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mnb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_Train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpredictions_NB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTrain_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'naive_bayes' is not defined"
     ]
    }
   ],
   "source": [
    "#Multinomial Naive Bayes\n",
    "nb = naive_bayes.MultinomialNB()\n",
    "nb.fit(Train_X, y_Train)\n",
    "predictions_NB = nb.predict(Train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Train_X_Tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-d28b09b4df02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulticlass\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOneVsOneClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOneVsOneClassifier\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTrain_X_Tfidf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTrain_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mpredictions_SVM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTest_X_Tfidf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Precision:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTest_Y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions_SVM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Train_X_Tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "#Multiclass\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "clf = OneVsOneClassifier( LinearSVC(random_state=0)).fit(Train_X_Tfidf, Train_Y)\n",
    "predictions_SVM = clf.predict(Test_X_Tfidf)\n",
    "print(\"Precision:\",metrics.precision_score(Test_Y, predictions_SVM))\n",
    "print(\"Recall:\",metrics.recall_score(Test_Y, predictions_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM_Classifier\n",
    "\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(Train_X,y_Train)\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(Test_X)\n",
    "#print(\"Precision:\",metrics.precision_score(y_Test, predictions_SVM))\n",
    "#print(\"Recall:\",metrics.recall_score(y_Test, predictions_SVM))\n",
    "predictions_SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [184, 92]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-208174171a74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#Generate the confusion matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mcf_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_Test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions_SVM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcf_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\new\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m     \"\"\"\n\u001b[1;32m--> 253\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\new\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \"\"\"\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\new\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 205\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [184, 92]"
     ]
    }
   ],
   "source": [
    "##Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Generate the confusion matrix\n",
    "cf_matrix = confusion_matrix(y_Test, predictions_SVM)\n",
    "\n",
    "print(cf_matrix)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()\n",
    "\n",
    "print (classification_report(y_Test, predictions_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the Classification\n",
    "\n",
    "test = ['<input class=\"quer\" type=\"text\" value=\"\" style=\"border: solid #b9b9b9 2px ; height: 3em; width: 78%; border-radius:10px; padding-left: 8%; font-size: 1.5em; font-weight: 600; outline: none; margin-top: 2%\" placeholder=\"Search\">']\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "element = [entry.lower() for entry in test]\n",
    "\n",
    "# Step - 1c : Tokenization : In this each entry in the corpus will be broken into set of words\n",
    "element= [word_tokenize(entry) for entry in test]\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "#element = [lemmatizer.lemmatize(word) for word in element if not word in set(stop_words)]\n",
    "\n",
    "final_words = []\n",
    "for word in element:\n",
    "    if word not in stopwords.words('english'):\n",
    "        final_words.append(word)\n",
    "        \n",
    "test_processed =[ ' '.join([lemmatizer.lemmatize(word) for word_list in element for word in word_list])]\n",
    "test_processed\n",
    "\n",
    "#test_input = Tfidf_vect.transform(test_processed)\n",
    "test_input = vectorizer.transform(test_processed)\n",
    "test_input.shape\n",
    "\n",
    "\n",
    "res= SVM.predict(test_input)[0]\n",
    "print(res,test_processed)\n",
    "if res==1:\n",
    "    print(\"Search\")\n",
    "elif res==0:\n",
    "    print(\"AddToCart\")\n",
    "elif res==2:\n",
    "    print(\"Checkout\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
